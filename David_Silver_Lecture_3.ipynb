{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "David Silver Lecture 3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asokraju/Rienforcement-Learning/blob/master/David_Silver_Lecture_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kiq0HPROdISP",
        "colab_type": "text"
      },
      "source": [
        "# Lecture 3 : Planning by Dynamic Programming\n",
        "\n",
        "This Document contains the simulation of examples provided in [Lecture 3](https://www.youtube.com/watch?v=Nd1-UUMVfz4&list=PLqYmG7hTraZDM-OYHWgPebj2MfCFzFObQ&index=3) of Introduction to Rienforcement Learning by David Silver\n",
        "\n",
        "Author: Krishna Chaitanya Kosaraju\n",
        "\n",
        "email: kkrishnachaitanya89@gmail.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4M8yX36d-3w",
        "colab_type": "text"
      },
      "source": [
        "#Part One: Grid World\n",
        "\n",
        "\n",
        "![Grid World](https://ibb.co/6Zt8RGG)\n",
        "\n",
        "There are a total of 16 states, in which  two are terminal states. Other states has four actions (Left, Right, Up, Down)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__Gkg1bsdgiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "random.seed(10)\n",
        "np.random.seed(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0ouxC5zeFop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Grid_world_MDP(s,a):\n",
        "  \"\"\"Given a state and action, it will give the next state and the reward\"\"\"\n",
        "  mdp = {'S0':{'Left' : (0, 'S0'), 'Right':(0, 'S0'), 'Up':(0, 'S0'), 'Down':(0, 'S0')}, # terminal state: no matter the action-- it remains in the same place\n",
        "         'S1':{'Left' : (-1, 'S0'), 'Right':(-1, 'S2'), 'Up':(-1, 'S1'), 'Down':(-1, 'S5')},\n",
        "         'S2':{'Left' : (-1, 'S1'), 'Right':(-1, 'S3'), 'Up':(-1, 'S2'), 'Down':(-1, 'S6')},\n",
        "         'S3':{'Left' : (-1, 'S2'), 'Right':(-1, 'S3'), 'Up':(-1, 'S3'), 'Down':(-1, 'S7')},\n",
        "         'S4':{'Left' : (-1, 'S4'), 'Right':(-1, 'S5'), 'Up':(-1, 'S0'), 'Down':(-1, 'S8')},\n",
        "         'S5':{'Left' : (-1, 'S4'), 'Right':(-1, 'S6'), 'Up':(-1, 'S1'), 'Down':(-1, 'S9')},\n",
        "         'S6':{'Left' : (-1, 'S5'), 'Right':(-1, 'S7'), 'Up':(-1, 'S2'), 'Down':(-1, 'S10')},\n",
        "         'S7':{'Left' : (-1, 'S6'), 'Right':(-1, 'S7'), 'Up':(-1, 'S3'), 'Down':(-1, 'S11')},\n",
        "         'S8':{'Left' : (-1, 'S8'), 'Right':(-1, 'S9'), 'Up':(-1, 'S4'), 'Down':(-1, 'S12')},\n",
        "         'S9':{'Left' : (-1, 'S8'), 'Right':(-1, 'S10'), 'Up':(-1, 'S5'), 'Down':(-1, 'S13')},\n",
        "         'S10':{'Left' : (-1, 'S9'), 'Right':(-1, 'S11'), 'Up':(-1, 'S6'), 'Down':(-1, 'S14')},\n",
        "         'S11':{'Left' : (-1, 'S10'), 'Right':(-1, 'S11'), 'Up':(-1, 'S7'), 'Down':(-1, 'S15')},\n",
        "         'S12':{'Left' : (-1, 'S12'), 'Right':(-1, 'S13'), 'Up':(-1, 'S8'), 'Down':(-1, 'S12')},\n",
        "         'S13':{'Left' : (-1, 'S12'), 'Right':(-1, 'S14'), 'Up':(-1, 'S9'), 'Down':(-1, 'S13')},\n",
        "         'S14':{'Left' : (-1, 'S13'), 'Right':(-1, 'S15'), 'Up':(-1, 'S10'), 'Down':(-1, 'S14')},\n",
        "         'S15':{'Left' : (0, 'S15'), 'Right':(0, 'S15'), 'Up':(0, 'S15'), 'Down':(0, 'S15')} #terminal state\n",
        "         }\n",
        "  return mdp[s][a]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD0AeFpVhx6W",
        "colab_type": "code",
        "outputId": "7a527bca-74b7-4372-c1f8-eee47af57b1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        }
      },
      "source": [
        "def Random_Agent(iter = 400, gamma = 1):\n",
        "  States = ['S0','S1','S2','S3','S4','S5','S6','S7','S8','S9','S10','S11','S12','S13','S14','S15']\n",
        "  Actions = ['Left', 'Right', 'Up', 'Down']\n",
        "  Q_init = {'S0':{'Left' : 0, 'Right': 0, 'Up':0, 'Down':0}, \n",
        "          'S1':{'Left' : 0, 'Right': 0, 'Up':0, 'Down':0},\n",
        "          'S2':{'Left' : 0, 'Right': 0, 'Up':0, 'Down':0},\n",
        "          'S3':{'Left' : 0, 'Right': 0, 'Up':0, 'Down':0},\n",
        "          'S4':{'Left' : 0, 'Right': 0, 'Up':0, 'Down':0},\n",
        "          'S5':{'Left' : 0, 'Right': 0, 'Up':0, 'Down':0},\n",
        "          'S6':{'Left' : 0, 'Right': 0, 'Up':0, 'Down':0},\n",
        "          'S7':{'Left' : 0, 'Right': 0, 'Up':0, 'Down':0},\n",
        "          'S8':{'Left' : 0, 'Right': 0, 'Up':0, 'Down':0},\n",
        "          'S9':{'Left' : 0, 'Right': 0, 'Up':0, 'Down':0},\n",
        "          'S10':{'Left' : 0, 'Right': 0, 'Up':0, 'Down':0},\n",
        "          'S11':{'Left' : 0, 'Right': 0, 'Up':0, 'Down':0},\n",
        "          'S12':{'Left' : 0, 'Right': 0, 'Up':0, 'Down':0},\n",
        "          'S13':{'Left' : 0, 'Right': 0, 'Up':0, 'Down':0},\n",
        "          'S14':{'Left' : 0, 'Right': 0, 'Up':0, 'Down':0},\n",
        "          'S15':{'Left' : 0, 'Right': 0, 'Up':0, 'Down':0},\n",
        "          }\n",
        "  V_init = {'S0':0,'S1':0,'S2':0,'S3':0,'S4':0,'S5':0,'S6':0,'S7':0,'S8':0,'S9':0,'S10':0,'S11':0,'S12':0,'S13':0,'S14':0,'S15':0}\n",
        "\n",
        "  for i in range(iter):\n",
        "    for s in States:\n",
        "      #Choosing a random action form Actions\n",
        "      a = random.choice(Actions)\n",
        "      reward, next_state = Grid_world_MDP(s,a)\n",
        "      # We use both Q and V to obtain them\n",
        "      # Q(s,a) = (reward(s,a) + gamma* Prob_transition *V(next_state|state, action))\n",
        "      # V(s) = sum of (Policy(s,a)*Q(s,a))_ for all actions\n",
        "      # The Environment is determenistic therefore Prob_trans =1\n",
        "      Q_init[s][a] = reward +gamma* 1* V_init[next_state]\n",
        "      temp = 0\n",
        "      for a in Actions:\n",
        "        temp = temp + (1/4)*Q_init[s][a]\n",
        "      V_init[s] = temp\n",
        "  return Q_init, V_init\n",
        "\n",
        "\n",
        "Q, V = Random_Agent()\n",
        "States = ['S0','S1','S2','S3','S4','S5','S6','S7','S8','S9','S10','S11','S12','S13','S14','S15']\n",
        "Actions = ['Left', 'Right', 'Up', 'Down']\n",
        "\n",
        "print(50*'*')\n",
        "print(\"The Value function is\")\n",
        "print(50*'*')\n",
        "for state in States:\n",
        "  print(state, np.round(V[state],2))\n",
        "print(50*'*')\n",
        "print(\"\\n\")\n",
        "print(50*'*')\n",
        "print(\"Acting greedily results in the follwing policy\")\n",
        "print(50*'*')\n",
        "\n",
        "for state in States:\n",
        "  #print(state, max(Q[state], key=Q[state].get))\n",
        "#print(50*'*')\n",
        "  sampleDict = Q[state]\n",
        "  itemMaxValue = max(sampleDict.items(), key=lambda x: x[1])\n",
        "  listOfKeys = list()\n",
        "  for key, value in sampleDict.items():\n",
        "    if np.round(value,2) == np.round(itemMaxValue[1],2):\n",
        "      listOfKeys.append(key)\n",
        "  print(state, listOfKeys)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**************************************************\n",
            "The Value function is\n",
            "**************************************************\n",
            "S0 0.0\n",
            "S1 -13.96\n",
            "S2 -19.94\n",
            "S3 -21.94\n",
            "S4 -13.96\n",
            "S5 -17.95\n",
            "S6 -19.95\n",
            "S7 -19.95\n",
            "S8 -19.94\n",
            "S9 -19.94\n",
            "S10 -17.95\n",
            "S11 -13.96\n",
            "S12 -21.93\n",
            "S13 -19.94\n",
            "S14 -13.96\n",
            "S15 0.0\n",
            "**************************************************\n",
            "\n",
            "\n",
            "**************************************************\n",
            "Acting greedily results in the follwing policy\n",
            "**************************************************\n",
            "S0 ['Left', 'Right', 'Up', 'Down']\n",
            "S1 ['Left']\n",
            "S2 ['Left']\n",
            "S3 ['Left', 'Down']\n",
            "S4 ['Up']\n",
            "S5 ['Left', 'Up']\n",
            "S6 ['Down']\n",
            "S7 ['Down']\n",
            "S8 ['Up']\n",
            "S9 ['Right', 'Up']\n",
            "S10 ['Right', 'Down']\n",
            "S11 ['Down']\n",
            "S12 ['Right', 'Up']\n",
            "S13 ['Right']\n",
            "S14 ['Right']\n",
            "S15 ['Left', 'Right', 'Up', 'Down']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hdMKlohd0UIR"
      },
      "source": [
        "# Part -- 2 : Car Rentals\n",
        "\n",
        "There two location with a maximum of twenty cars at each location. Cars are requested and returned randomly:\n",
        "1. Requests and returns follow Poisson Distribution $\\dfrac{\\lambda^n }{n!}e^{-\\lambda}$\n",
        "2. Location Requests and returns follow Poisson Distribution with $\\lambda =3$.\n",
        "3. Location Requests and returns follow Poisson Distribution with $\\lambda =4$ and $\\lambda =2$, respectively.\n",
        "\n",
        "Actions: move upto 5 cars from each location.\n",
        "\n",
        "Reward: $10 dollors if some-one rent a car!\n",
        "\n",
        "We have two states $0\\leq Loc1 \\leq 20$ and $0 \\leq Loc2 \\leq 20$.\n",
        "\n",
        "six actions 0, 1, 2, 3, 4, 5 cars moved from Loc1 to Loc2 or vice versa.\n",
        "\n",
        "\n",
        "Note: Question may be a bit incomplete, If we have 20 cars at a location and someone tries to return it, what will happen?\n",
        "\n",
        "\n",
        "Its incomplete set of rules... not gonna work on this"
      ]
    }
  ]
}